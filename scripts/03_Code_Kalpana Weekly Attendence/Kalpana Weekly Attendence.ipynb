{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdaa12de",
   "metadata": {
    "id": "cdaa12de"
   },
   "outputs": [],
   "source": [
    "# importing required modules\n",
    "import pandas as pd\n",
    "import mysql.connector as msql\n",
    "import math\n",
    "import os\n",
    "import datetime\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7376b6be",
   "metadata": {
    "id": "7376b6be"
   },
   "outputs": [],
   "source": [
    "#display all columns and rows\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce45742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from She for STEM - Uttarakhand.csv:\n"
     ]
    }
   ],
   "source": [
    "#Reading She for STEM Incubator file present on source files\n",
    "directory_path =(r\"\")\n",
    "csv_files = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(directory_path, file)\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(f\"Data from {file}:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41411f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with 'email' column and columns that start with 'Week' 'Video', 'Recording', and 'Master class'\n",
    "da = data[['Email'] + [col for col in data.columns if col.startswith(('Week','Video', 'SUK', 'Workshop', 'Master Class'))]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7c9070d-687e-49d9-9993-c36ef100ff1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(503, 48)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03d20a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldcol = list(da.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43e0ee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldcol = [col for col in oldcol if not col.startswith(\"Week\")]\n",
    "oldcol = [col.split(\" :\")[0] for col in oldcol]\n",
    "oldcol = [col.split(\": \")[0] for col in oldcol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3904b822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables to keep track of the current week, video count, recording count, and master class count\n",
    "week_col = None\n",
    "video_count = 0\n",
    "recording_count = 0\n",
    "master_count = 0\n",
    "workshop_count = 0\n",
    "\n",
    "# Create an empty list to store the new column names\n",
    "new_cols = []\n",
    "\n",
    "# Iterate over each column in the data\n",
    "for col in data.columns:\n",
    "    # If the column starts with 'Week'\n",
    "    if col.startswith('Week'):\n",
    "        # Split the column name by space and get the second element (the week number)\n",
    "        week_col = col.split()[1]\n",
    "        # Reset the video, recording, and master class counts for the new week\n",
    "        video_count = 0\n",
    "        recording_count = 0\n",
    "    # If the column starts with 'Video'\n",
    "    elif col.startswith('Video'):\n",
    "        # Increment the video count for the current week\n",
    "        video_count += 1\n",
    "        # Append a new column name to the list using f-string formatting\n",
    "        new_cols.append(f'WK{week_col}_V{video_count}')\n",
    "    # If the column starts with 'Workshop'\n",
    "    elif col.startswith('Workshop'):\n",
    "        # Increment the master class count for the current week\n",
    "        workshop_count += 1\n",
    "        # Append a new column name to the list using f-string formatting\n",
    "        new_cols.append(f'WK{week_col}_WS{workshop_count}')\n",
    "    # If the column doesn't start with any of the above prefixes\n",
    "    # If the column starts with 'Recording'\n",
    "    elif col.startswith('SUK'):\n",
    "        # Increment the recording count for the current week\n",
    "        recording_count += 1\n",
    "        # Append a new column name to the list using f-string formatting\n",
    "        new_cols.append(f'WK{week_col}_SUK_V')\n",
    "    # If the column starts with 'Master Class'\n",
    "    elif col.startswith('Master Class'):\n",
    "        # Increment the master class count for the current week\n",
    "        master_count += 1\n",
    "        # Append a new column name to the list using f-string formatting\n",
    "        new_cols.append(f'WK{week_col}_Master{master_count}')\n",
    "    # If the column doesn't start with any of the above prefixes\n",
    "    else:\n",
    "        # Append the original column name to the list\n",
    "        new_cols.append(col)\n",
    "\n",
    "# Remove all columns that start with 'Week' from the data\n",
    "data = data.loc[:, ~data.columns.str.startswith('Week')]\n",
    "# Assign the new column names to the data\n",
    "data.columns = new_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ac50c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Incubator_and_attendence_monitoring from Outout files\n",
    "data =pd.read_csv(r\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab41808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data[\"Email\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebcab69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of columns starting with 'WK' or 'Email'\n",
    "selected_columns = [col for col in data.columns if col.startswith('WK') or col.lower() == 'email']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "733432b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the selected columns in the DataFrame\n",
    "data = data[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e59bba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_col=list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bedad0de-60e6-416f-a15f-caa397602fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Email', 'WK0_V1', 'WK0_V2', 'WK0_SUK_V', 'WK1_V1', 'WK1_V2', 'WK1_WS1',\n",
       "       'WK1_Master1', 'WK2_SUK_V', 'WK3_V1', 'WK3_V2', 'WK3_WS2',\n",
       "       'WK3_Master2', 'WK4_SUK_V', 'WK4_WS3', 'WK5_V1', 'WK5_V2', 'WK5_V3',\n",
       "       'WK5_WS4', 'WK5_WS5', 'WK5_Master3', 'WK6_WS6', 'WK6_SUK_V', 'WK7_V1',\n",
       "       'WK7_WS7', 'WK9_V1', 'WK9_V2', 'WK9_WS8', 'WK9_Master4', 'WK10_V1',\n",
       "       'WK10_V2', 'WK10_V3', 'WK10_V4', 'WK10_WS9', 'WK10_Master5',\n",
       "       'WK10_WS10', 'WK10_SUK_V'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d939f102-8799-48b6-8a0c-3b567e453ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Email',\n",
       " 'Video !',\n",
       " 'Video @',\n",
       " 'SUK +',\n",
       " 'Video #',\n",
       " 'Video $',\n",
       " 'Workshop @',\n",
       " 'Master Class #',\n",
       " 'SUK !',\n",
       " 'Video %',\n",
       " 'Video ^',\n",
       " 'Workshop $',\n",
       " 'Master Class $',\n",
       " 'SUK @',\n",
       " 'Workshop !!',\n",
       " 'Video $?',\n",
       " 'Video %+',\n",
       " 'Video %!',\n",
       " 'Workshop !#',\n",
       " 'Workshop %',\n",
       " 'Master Class !',\n",
       " 'Workshop ^',\n",
       " 'SUK #',\n",
       " 'Video %@',\n",
       " 'Workshop &',\n",
       " 'Video %#',\n",
       " 'Video %$',\n",
       " 'Workshop *',\n",
       " 'Master Class %',\n",
       " 'Video &',\n",
       " 'Video *',\n",
       " 'Video ?',\n",
       " 'Video !+',\n",
       " 'Workshop ?',\n",
       " 'Master Class !^',\n",
       " 'Workshop !@',\n",
       " 'SUK $']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oldcol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82984dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = oldcol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38f9560e-c8cb-42f6-9430-3e0c767a9dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the column names\n",
    "def clean_column_name(name):\n",
    "    return name.split(':')[0]\n",
    "\n",
    "# Apply the function to the column names\n",
    "data.columns = [clean_column_name(col) for col in data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44989c8e-bff9-4eef-bd0c-4935a45ac95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_column(col):\n",
    "    # Split the column name by space\n",
    "    parts = col.split()\n",
    "    special_chars = {'!': '1', '@': '2', '#': '3', '$': '4', '%': '5', '^': '6', '&': '7', '*': '8', '?': '9', '+': '0'}\n",
    "    \n",
    "    # If the first part is 'SUK', add the number corresponding to the last character\n",
    "    if parts[0] == 'SUK':\n",
    "        return parts[0] + special_chars.get(parts[1][-1], '0')\n",
    "    \n",
    "    # If the first part is 'Video', use the prefix 'VID' and the numbers corresponding to the last two characters\n",
    "    elif parts[0] == 'Video':\n",
    "        last_char = parts[1][-1]\n",
    "        second_last_char = parts[1][-2] if len(parts[1]) > 1 else '+'\n",
    "        return 'VID' + special_chars.get(second_last_char, '0') + special_chars.get(last_char, '0')\n",
    "\n",
    "    # If the first part is 'Workshop', use the prefix 'VID' and the numbers corresponding to the last two characters\n",
    "    elif parts[0] == 'Workshop':\n",
    "        last_char = parts[1][-1]\n",
    "        second_last_char = parts[1][-2] if len(parts[1]) > 1 else '+'\n",
    "        return 'WS' + special_chars.get(second_last_char, '0') + special_chars.get(last_char, '0')\n",
    "    \n",
    "    # If the first part contains 'Master' and 'Class' is present, use the prefix 'MC' and the numbers corresponding to the last two characters\n",
    "    elif 'Master' in parts and 'Class' in parts:\n",
    "        index = parts.index('Master')\n",
    "        last_char = parts[index + 2][-1]\n",
    "        second_last_char = parts[index + 2][-2] if len(parts[index + 2]) > 1 else '+'\n",
    "        return 'MC' + special_chars.get(second_last_char, '0') + special_chars.get(last_char, '0')\n",
    "    \n",
    "    # Otherwise, return the column name as it is\n",
    "    else:\n",
    "        return col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1f37e36-5d54-4861-b8d1-fba16b63d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column names using the rename_column function\n",
    "data.rename(columns=rename_column, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd00a022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Excel file form our source i.e Timestamp_of_Videos\n",
    "excel_file  = pd.read_excel(r\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1abcde39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Email' present in 'data' but not in the Excel file. Skipping.\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each column in the 'data' DataFrame\n",
    "for column_name in data.columns:\n",
    "    # Check if the column exists in the Excel file\n",
    "    if column_name in excel_file['Code'].values:\n",
    "        # Get the corresponding value in the \"Time\" column from the Excel file\n",
    "        value = excel_file.loc[excel_file['Code'] == column_name, 'Time'].values[0]\n",
    "        \n",
    "        # Calculate the percentage value\n",
    "        percentage_value = (data[column_name] * 100) / (value/3600)\n",
    "        \n",
    "        # Assign the calculated percentage value to a new column in the \"data1\" DataFrame with the same name as the \"Code\" column\n",
    "        df[column_name] = percentage_value\n",
    "    else:\n",
    "        # Handle the case when the column is present in 'data' but not in the Excel file\n",
    "        print(f\"Column '{column_name}' present in 'data' but not in the Excel file. Skipping.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d546fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming column name with old name\n",
    "df.columns = rename_col \n",
    "data.columns = rename_col "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1df694ae",
   "metadata": {
    "id": "1df694ae"
   },
   "outputs": [],
   "source": [
    "# Changing percent values greater than 100 to 100\n",
    "def Max_Value(value):\n",
    "    if value >=100:\n",
    "        return 100\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adc89c77",
   "metadata": {
    "id": "adc89c77"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\spjay\\AppData\\Local\\Temp\\ipykernel_4768\\2444152655.py:3: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[df1]=df[df1].applymap(Max_Value)\n"
     ]
    }
   ],
   "source": [
    "col=df.iloc[:,1:]\n",
    "df1=col.columns\n",
    "df[df1]=df[df1].applymap(Max_Value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bece29c5",
   "metadata": {
    "id": "bece29c5"
   },
   "source": [
    "# ðŸ‘‡ Define Week Here  ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5f44402",
   "metadata": {
    "id": "e5f44402"
   },
   "outputs": [],
   "source": [
    "end_week = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87419cb9",
   "metadata": {
    "id": "87419cb9"
   },
   "source": [
    "# Weekly Recorded Total Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1149c00",
   "metadata": {
    "id": "d1149c00"
   },
   "outputs": [],
   "source": [
    "cols_to_select = ['Email']  # Start with 'email' column as the first column\n",
    "for week in range(end_week + 1):\n",
    "    video_cols = [f'WK{week}_V{video}' for video in range(1, 10)]\n",
    "    video_cols = [col for col in video_cols if col in data.columns and col != 'email']\n",
    "    cols_to_select.extend(video_cols)\n",
    "\n",
    "# Select the desired columns and create a new DataFrame\n",
    "Weekly = data[cols_to_select].copy()\n",
    "\n",
    "# Calculate total for each week and add to Weekly dataframe\n",
    "for week in range(end_week + 1):\n",
    "    video_cols = [f'WK{week}_V{video}' for video in range(1, 10)]\n",
    "    video_cols = [col for col in video_cols if col in Weekly.columns]\n",
    "    Weekly[f'WK{week}_Pre_Recorded_Total'] = Weekly[video_cols].sum(axis=1, skipna=True)\n",
    "\n",
    "# Calculate total for all weeks and add to Weekly dataframe\n",
    "total_cols = [f'WK{week}_Pre_Recorded_Total' for week in range(end_week + 1) if f'WK{week}_Pre_Recorded_Total' in Weekly.columns]\n",
    "Weekly['Pre_Recorded_All_Week_Total'] = Weekly[total_cols].sum(axis=1, skipna=True)\n",
    "\n",
    "# Select the desired columns in the Weekly dataframe\n",
    "cols_to_select = ['Email'] + total_cols + ['Pre_Recorded_All_Week_Total']\n",
    "Weekly = Weekly[cols_to_select]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7a05d8",
   "metadata": {
    "id": "8f7a05d8"
   },
   "source": [
    "# Recorded Weekly Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f5ca5d1",
   "metadata": {
    "id": "4f5ca5d1"
   },
   "outputs": [],
   "source": [
    "cols_to_select = ['Email']  # Start with 'email' column as the first column\n",
    "for week in range(end_week + 1):\n",
    "    video_cols = [f'WK{week}_V{video}' for video in range(1, 10)]\n",
    "    video_cols = [col for col in video_cols if col in df.columns and col != 'email']\n",
    "    cols_to_select.extend(video_cols)\n",
    "\n",
    "# Select the desired columns and create a new DataFrame\n",
    "Weekly_Per = df[cols_to_select].copy()\n",
    "\n",
    "# Calculate total for each week\n",
    "for week in range(end_week + 1):\n",
    "    video_cols = [f'WK{week}_V{video}' for video in range(1, 10)]\n",
    "    video_cols = [col for col in video_cols if col in Weekly_Per.columns]\n",
    "    Weekly_Per[f'Pre_Recorded_WK{week}_Percent'] = Weekly_Per[video_cols].mean(axis=1, skipna=True)\n",
    "\n",
    "# Calculate total for all weeks\n",
    "total_cols = [f'Pre_Recorded_WK{week}_Percent' for week in range(end_week + 1) if f'Pre_Recorded_WK{week}_Percent' in Weekly_Per.columns]\n",
    "Weekly_Per['Pre_Recorded_All_Week_Percent'] = Weekly_Per[total_cols].mean(axis=1, skipna=True)\n",
    "\n",
    "# Select the desired columns in the Weekly dataframe\n",
    "cols_to_select = ['Email'] + total_cols + ['Pre_Recorded_All_Week_Percent']\n",
    "Weekly_Per = Weekly_Per[cols_to_select]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a207f233",
   "metadata": {
    "id": "a207f233"
   },
   "outputs": [],
   "source": [
    "# Merging Dataframe\n",
    "Weekly = Weekly.merge(Weekly_Per,on= 'Email', how ='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e9ca57",
   "metadata": {
    "id": "31e9ca57"
   },
   "source": [
    "# SUK Weekly Total Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "377a9050-d6f1-4728-b376-38f0c9628a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the list of columns to select\n",
    "cols_to_select = []\n",
    "for week in range(end_week + 1):\n",
    "    col_name = f'WK{week}_SUK_V'\n",
    "    if col_name in data.columns:\n",
    "        cols_to_select.append(col_name)\n",
    "\n",
    "# Add the 'Email' column to the list of selected columns\n",
    "cols_to_select.append('Email')\n",
    "\n",
    "# Select the desired columns and create a new DataFrame\n",
    "SUK_Recorded_Total = data.loc[:, cols_to_select]\n",
    "\n",
    "# Create new columns with 'SUK' prefix for each week\n",
    "for week in range(end_week + 1):\n",
    "    col_name = f'WK{week}_SUK_V'\n",
    "    new_col_name = f'SUK{week + 1}'\n",
    "    if col_name in SUK_Recorded_Total.columns:\n",
    "        SUK_Recorded_Total[new_col_name] = SUK_Recorded_Total[col_name]\n",
    "\n",
    "# Drop the original columns (excluding 'Email')\n",
    "cols_to_drop = [col for col in cols_to_select if col != 'Email']\n",
    "SUK_Recorded_Total.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Select only the columns of float data type for calculating total hours\n",
    "float_cols = SUK_Recorded_Total.select_dtypes(include='float')\n",
    "\n",
    "# Calculate the sum of hours for each row and add as a new column\n",
    "SUK_Recorded_Total['SUK_Total_Hours'] = float_cols.sum(axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f485caf",
   "metadata": {
    "id": "3f485caf"
   },
   "outputs": [],
   "source": [
    "# Merging Dataframe\n",
    "Weekly = Weekly.merge(SUK_Recorded_Total,on= 'Email', how ='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eb456f",
   "metadata": {
    "id": "39eb456f"
   },
   "source": [
    "# SUK Average Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e430506b",
   "metadata": {
    "id": "e430506b"
   },
   "outputs": [],
   "source": [
    "# Create a list of all column names up to the end week\n",
    "cols_to_select = []\n",
    "for week in range(end_week + 1):\n",
    "    col_name = f'WK{week}_SUK_V'\n",
    "    if col_name in df.columns:\n",
    "        cols_to_select.append(col_name)\n",
    "\n",
    "# Add the 'email' column to the list of selected columns\n",
    "cols_to_select.append('Email')\n",
    "\n",
    "# Select the desired columns and create a new DataFrame\n",
    "SUK_Recorded_percent = df.loc[:, cols_to_select]\n",
    "\n",
    "# Create new columns with 'SUK' prefix for each week\n",
    "for week in range(end_week + 1):\n",
    "    col_name = f'WK{week}_SUK_V'\n",
    "    new_col_name = f'SUK{week+1}_Percent'\n",
    "    if col_name in SUK_Recorded_percent.columns:\n",
    "        SUK_Recorded_percent[new_col_name] = SUK_Recorded_percent[col_name]\n",
    "\n",
    "# Drop the original columns\n",
    "SUK_Recorded_percent.drop(cols_to_select[:-1], axis=1, inplace=True)\n",
    "\n",
    "# Select only the columns of float data type\n",
    "float_cols = SUK_Recorded_percent.select_dtypes(include='float')\n",
    "\n",
    "# Calculate the mean of the float columns\n",
    "SUK_Recorded_percent['SUK_Percentage'] = float_cols.mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74d10c54",
   "metadata": {
    "id": "74d10c54"
   },
   "outputs": [],
   "source": [
    "# Merging Dataframe\n",
    "Weekly = Weekly.merge(SUK_Recorded_percent,on= 'Email', how ='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c08154f",
   "metadata": {
    "id": "6c08154f"
   },
   "source": [
    "# Weekly Masterclass total hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "HNLONtNqTaXO",
   "metadata": {
    "id": "HNLONtNqTaXO"
   },
   "outputs": [],
   "source": [
    "# Create a list of all column names up to the end week\n",
    "cols_to_select = [f'WK{i}_Master{j}' for i in range(end_week + 2) for j in range(1, 10) if f'WK{i}_Master{j}' in data.columns]\n",
    "\n",
    "# Add the 'email' column to the list of selected columns\n",
    "cols_to_select.append('Email')\n",
    "\n",
    "# Select the desired columns and create a new DataFrame\n",
    "Masterclass_Total = data.loc[:, cols_to_select]\n",
    "\n",
    "# Rename columns as \"Master{number}\"\n",
    "Masterclass_Total = Masterclass_Total.rename(columns={col_name: f'Master{i+1}' for i, col_name in enumerate(Masterclass_Total.columns) if col_name != 'Email'})\n",
    "\n",
    "# Create the \"Total_Hours\" column\n",
    "Masterclass_Total['Masterclass_Total_Hours'] = Masterclass_Total.select_dtypes(include=['float']).sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fNhbMxrFS9TZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fNhbMxrFS9TZ",
    "outputId": "a53a7359-c92e-4936-9473-ddeeeb508373"
   },
   "outputs": [],
   "source": [
    "# Merging Dataframe\n",
    "Weekly = Weekly.merge(Masterclass_Total,on= 'Email', how ='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DQuNQ0_HXcPk",
   "metadata": {
    "id": "DQuNQ0_HXcPk"
   },
   "source": [
    "# Masterclass Percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "z9wwBUZJVuYJ",
   "metadata": {
    "id": "z9wwBUZJVuYJ"
   },
   "outputs": [],
   "source": [
    "# Create a list of all column names up to the end week\n",
    "cols_to_select = [f'WK{i}_Master{j}' for i in range(end_week + 2) for j in range(1, 10) if f'WK{i}_Master{j}' in df.columns]\n",
    "\n",
    "# Add the 'email' column to the list of selected columns\n",
    "cols_to_select.append('Email')\n",
    "\n",
    "# Select the desired columns and create a new DataFrame\n",
    "Masterclass_Per = df.loc[:, cols_to_select]\n",
    "\n",
    "# Rename columns as \"Master{number}\"\n",
    "Masterclass_Per = Masterclass_Per.rename(columns={col_name: f'Master{i +1}_Percent' for i, col_name in enumerate(Masterclass_Per.columns) if col_name != 'Email'})\n",
    "\n",
    "# Create the \"Master_Percentage\" column\n",
    "Masterclass_Per['Master_Percentage'] = Masterclass_Per.select_dtypes(include=['float']).mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "vzm5imoQZBsx",
   "metadata": {
    "id": "vzm5imoQZBsx"
   },
   "outputs": [],
   "source": [
    "# Merging Dataframe\n",
    "Weekly = Weekly.merge(Masterclass_Per,on= 'Email', how ='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7301ace2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Email', 'WK0_Pre_Recorded_Total', 'WK1_Pre_Recorded_Total',\n",
       "       'WK2_Pre_Recorded_Total', 'WK3_Pre_Recorded_Total',\n",
       "       'WK4_Pre_Recorded_Total', 'WK5_Pre_Recorded_Total',\n",
       "       'WK6_Pre_Recorded_Total', 'WK7_Pre_Recorded_Total',\n",
       "       'WK8_Pre_Recorded_Total', 'WK9_Pre_Recorded_Total',\n",
       "       'WK10_Pre_Recorded_Total', 'Pre_Recorded_All_Week_Total',\n",
       "       'Pre_Recorded_WK0_Percent', 'Pre_Recorded_WK1_Percent',\n",
       "       'Pre_Recorded_WK2_Percent', 'Pre_Recorded_WK3_Percent',\n",
       "       'Pre_Recorded_WK4_Percent', 'Pre_Recorded_WK5_Percent',\n",
       "       'Pre_Recorded_WK6_Percent', 'Pre_Recorded_WK7_Percent',\n",
       "       'Pre_Recorded_WK8_Percent', 'Pre_Recorded_WK9_Percent',\n",
       "       'Pre_Recorded_WK10_Percent', 'Pre_Recorded_All_Week_Percent', 'SUK1',\n",
       "       'SUK3', 'SUK5', 'SUK7', 'SUK11', 'SUK_Total_Hours', 'SUK1_Percent',\n",
       "       'SUK3_Percent', 'SUK5_Percent', 'SUK7_Percent', 'SUK11_Percent',\n",
       "       'SUK_Percentage', 'Master1', 'Master2', 'Master3', 'Master4', 'Master5',\n",
       "       'Masterclass_Total_Hours', 'Master1_Percent', 'Master2_Percent',\n",
       "       'Master3_Percent', 'Master4_Percent', 'Master5_Percent',\n",
       "       'Master_Percentage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Weekly.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f05fdd-7bbb-49d0-98f6-35417d3b8b4b",
   "metadata": {},
   "source": [
    "# Weekly Workshop total hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c224bb3d-b0a8-4edb-9e1b-3566cdde93b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all column names up to the end week\n",
    "cols_to_select = [f'WK{i}_WS{j}' for i in range(end_week + 1) for j in range(1, 10) if f'WK{i}_WS{j}' in data.columns]\n",
    "\n",
    "# Add the 'email' column to the list of selected columns\n",
    "cols_to_select.append('Email')\n",
    "\n",
    "# Select the desired columns and create a new DataFrame\n",
    "Workshop_Total = data.loc[:, cols_to_select]\n",
    "\n",
    "# Rename columns as \"Workshop{number}\"\n",
    "Workshop_Total = Workshop_Total.rename(columns={col_name: f'Workshop{i+1}' for i, col_name in enumerate(Workshop_Total.columns) if col_name != 'Email'})\n",
    "\n",
    "# Create the \"Total_Hours\" column\n",
    "Workshop_Total['Workshop_Total_Hours'] = Workshop_Total.select_dtypes(include=['float']).sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "82337691-96dc-4d7f-bdd8-fa161102e47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Dataframe\n",
    "Weekly = Weekly.merge(Workshop_Total,on= 'Email', how ='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e236a6f-a3f1-4d74-8b61-3824c1263b54",
   "metadata": {},
   "source": [
    "# Workshop Percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0510d8bf-b45d-49bb-93e4-28b72237b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all column names up to the end week\n",
    "cols_to_select = [f'WK{i}_WS{j}' for i in range(end_week + 1) for j in range(1, 10) if f'WK{i}_WS{j}' in df.columns]\n",
    "\n",
    "# Add the 'email' column to the list of selected columns\n",
    "cols_to_select.append('Email')\n",
    "\n",
    "# Select the desired columns and create a new DataFrame\n",
    "Workshop_Per = df.loc[:, cols_to_select]\n",
    "\n",
    "# Rename columns as \"Master{number}\"\n",
    "Workshop_Per = Workshop_Per.rename(columns={col_name: f'Workshop{i +1}_Percent' for i, col_name in enumerate(Workshop_Per.columns) if col_name != 'Email'})\n",
    "\n",
    "# Create the \"Master_Percentage\" column\n",
    "Workshop_Per['Workshop_Percentage'] = Workshop_Per.select_dtypes(include=['float']).mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b4bb5c01-37a6-4b33-a5f1-d0bbfd2e01ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Dataframe\n",
    "Weekly = Weekly.merge(Workshop_Per,on= 'Email', how ='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d36a9e15-e566-4550-95fe-5e9514e75d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean email addresses\n",
    "def clean_email(email):\n",
    "\n",
    "    # Convert to lowercase and remove extra spaces\n",
    "    cleaned_email = email.lower().strip()\n",
    "    # Remove patterns like \".com.1\"\n",
    "    cleaned_email = re.sub(r'\\.com\\.\\d+', '.com', cleaned_email)\n",
    "    return cleaned_email\n",
    "\n",
    "# Apply the function to the 'email' column\n",
    "Weekly['Email'] = Weekly['Email'].apply(clean_email)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4937fb6a-377f-4cc0-8591-e148ecf73037",
   "metadata": {},
   "source": [
    "# Adding Genral Info and Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad203d5-2028-48e3-b27f-f1dc528cdc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gi = pd.read_csv(r\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06cea03c-564b-4996-8296-f1fa68c19d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "gi = gi[['Email', 'Name', 'Phone', 'Name_of_College_University','Currently_Pursuing_Degree']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac1244af-7827-46aa-a0a7-d42c55bbafd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with gi\n",
    "output = pd.merge(gi, Weekly, on='Email', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "35a9a227-5304-492b-8fd9-1b1d9ba2f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output =output.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "28f2cf59-dc96-4974-895e-f015b3b8bd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Null values with zero and rounding off upto 2 decimal points\n",
    "output=output.fillna(0)\n",
    "output=output.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9e1d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting data to Output files\n",
    "output.to_csv(r\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a552ae67-1df2-4ed5-b63f-c494ce9df1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1160f11d",
   "metadata": {},
   "source": [
    "# Storing data to MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fc9ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to MySQL Database\n",
    "conn= msql.connect(host='',user='',password=\"\",database=\"\",auth_plugin='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "25e19ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor =conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "07d159df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your existing code for inserting data into the database table\n",
    "for i, row in Weekly.iterrows():\n",
    "    row = [None if isinstance(val, float) and math.isnan(val) else val for val in row] # replace \"nan\" values with None\n",
    "    columns = ','.join(Weekly.columns)\n",
    "    placeholders = ','.join(['%s']*len(row))\n",
    "    # Construct the INSERT query with ON DUPLICATE KEY UPDATE clause\n",
    "    query = f\"INSERT INTO 09_weekly_attendence ({columns}) VALUES ({placeholders}) ON DUPLICATE KEY UPDATE \"\n",
    "    query += \", \".join([f\"{col}=VALUES({col})\" for col in Weekly.columns if col != 'Email'])\n",
    "    # Execute the query\n",
    "    cursor.execute(query, tuple(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb6b6cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y3HsWKP6XUCc",
   "metadata": {
    "id": "Y3HsWKP6XUCc"
   },
   "source": [
    "# Storing Data in Supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c36cfb-461b-4935-8e38-37a51007ee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supabase URL and API key\n",
    "url = ''\n",
    "api_key = ''\n",
    "\n",
    "\n",
    "# Headers for the request\n",
    "headers = {\n",
    "    'apikey': api_key,\n",
    "    'Authorization': f'Bearer {api_key}',\n",
    "    'Content-Type': 'application/json',\n",
    "    'Prefer': 'resolution=merge-duplicates'  # Enable upsert functionality\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6d55c300-4031-4b7c-a1f0-34a62da52a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 09_weekly_attendence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "62aaaf8f-71ea-4f67-aafe-47207997daeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final batch of 639 rows upserted successfully\n"
     ]
    }
   ],
   "source": [
    "table_name = '09_weekly_attendence'\n",
    "\n",
    "# Batch size for upserting\n",
    "batch_size = 1000  # You can adjust this value based on your performance needs\n",
    "\n",
    "# List to store rows before sending them in batches\n",
    "batch_data = []\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for i, row in Weekly.iterrows():\n",
    "    # Replace NaN values with None\n",
    "    row = [None if isinstance(val, float) and math.isnan(val) else val for val in row]\n",
    "    # Convert row to a dictionary\n",
    "    row_dict = dict(zip(Weekly.columns, row))\n",
    "    \n",
    "    # Add the row to the batch\n",
    "    batch_data.append(row_dict)\n",
    "    \n",
    "    # If the batch size is reached, send the data\n",
    "    if len(batch_data) >= batch_size:\n",
    "        # Send a batch of rows\n",
    "        response = requests.post(f'{url}/rest/v1/{table_name}', headers=headers, json=batch_data)\n",
    "        \n",
    "        # Check response\n",
    "        if response.status_code in [200, 201]:\n",
    "            print(f'Batch of {len(batch_data)} rows upserted successfully')\n",
    "        else:\n",
    "            print(f'Failed to upsert batch: {response.status_code}, {response.text}')\n",
    "        \n",
    "        # Clear the batch after sending\n",
    "        batch_data = []\n",
    "\n",
    "# Send any remaining rows in the last batch\n",
    "if batch_data:\n",
    "    response = requests.post(f'{url}/rest/v1/{table_name}', headers=headers, json=batch_data)\n",
    "    \n",
    "    if response.status_code in [200, 201]:\n",
    "        print(f'Final batch of {len(batch_data)} rows upserted successfully')\n",
    "    else:\n",
    "        print(f'Failed to upsert final batch: {response.status_code}, {response.text}')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
