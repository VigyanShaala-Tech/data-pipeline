{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "200d51ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing library\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import math \n",
    "import mysql.connector as msql\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1893e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying all columns and rows\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595d0243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking files from define path which are in csv format\n",
    "path = r''\n",
    "\n",
    "# Change the current working directory to the specified path\n",
    "os.chdir(path)\n",
    "\n",
    "# Use glob to get a list of file paths for all CSV files in the current directory\n",
    "file_paths = glob.glob('*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d05b0196",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create an empty list to store the keywords\n",
    "keywords = []\n",
    "\n",
    "# Create an empty dictionary to store the dataframes\n",
    "dataframes = {}\n",
    "\n",
    "# Iterate through each file path in the list of file paths\n",
    "for file in file_paths:\n",
    "    # Find the starting position of the keyword by searching for 'Assignment_'\n",
    "    start = file.find('Assignment_') + len('Assignment_')\n",
    "    \n",
    "    # Find the ending position of the keyword by searching for '.csv'\n",
    "    end = file.rfind('.csv')\n",
    "    \n",
    "    # Extract the keyword from the file path, removing leading/trailing spaces, and replacing spaces with underscores\n",
    "    keyword = file[start:end].strip().replace(' ', '_')\n",
    "    \n",
    "    # Add the extracted keyword to the list of keywords\n",
    "    keywords.append(keyword)\n",
    "    \n",
    "    # Read the CSV file and store it in a dataframe with the keyword as the key in the dataframes dictionary\n",
    "    dataframes[keyword] = pd.read_csv(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b05bff96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Career_Action_Plan_(CAP)',\n",
       " 'Career_Exploration',\n",
       " 'CV__Resume',\n",
       " 'Goal_Setting',\n",
       " 'LinkedIn',\n",
       " 'Searching_Internship',\n",
       " 'SMART_goals']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of keyword of our csv file present in our folder\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7b4a310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each keyword in the list of keywords\n",
    "for keyword in keywords:\n",
    "    # Assign the corresponding dataframe to a variable with the same name as the keyword\n",
    "    # This is done by using the globals() function to create a new variable in the global namespace\n",
    "    globals()[keyword] = dataframes[keyword]\n",
    "\n",
    "    # We have use golabl function to create dataframe of keyword so it should take name of dataframe as keyword. Like Swot will be name of datafarme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511c5075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from She for STEM - Uttarakhand.csv:\n"
     ]
    }
   ],
   "source": [
    "# Reading Kalpana SHE for STEM Incubator file from Source files\n",
    "\n",
    "directory_path =(r\"\")\n",
    "\n",
    "csv_files = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(directory_path, file)\n",
    "    Kalpana = pd.read_csv(file_path,usecols=['Email'])\n",
    "    print(f\"Data from {file}:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86579c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe to store the final results\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "# Create a dictionary to store comments for each keyword\n",
    "comments_dict = {}\n",
    "\n",
    "# Iterate through each keyword in the list of keywords\n",
    "for keyword in keywords:\n",
    "    # Filter the columns based on specific conditions...\n",
    "    filtered_columns = [col for col in globals()[keyword] if ('message' in col) or ('email' in col) or (col == 'status')]\n",
    "\n",
    "    new_df = globals()[keyword][filtered_columns]\n",
    "    \n",
    "    message_columns = [col for col in new_df.columns if 'message' in col]\n",
    "    new_df[message_columns] = new_df[message_columns].fillna('')\n",
    "    \n",
    "    # Create a new 'Comment' column by joining the values of the 'message' columns for each row\n",
    "    comment_col_name = 'Comment_' + keyword\n",
    "    new_df[comment_col_name] = new_df[message_columns].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "    \n",
    "    # Store the comments column name in the dictionary\n",
    "    comments_dict[keyword] = comment_col_name\n",
    "    \n",
    "    # Modify the 'Email' column by removing a specific prefix from the values\n",
    "    new_df['Email'] = new_df['user/email'].str.replace('vigyanshaalainternational1617-', '')\n",
    "    \n",
    "    # Rename the 'status' column to the keyword\n",
    "    new_df = new_df.rename(columns={'status': keyword})\n",
    "    \n",
    "    # Select the desired columns for the new dataframe\n",
    "    selected_columns = ['Email', keyword, comment_col_name]\n",
    "    new_df = new_df[selected_columns]\n",
    "    \n",
    "    # If the final dataframe is empty, assign it as the new_df\n",
    "    if final_df.empty:\n",
    "        final_df = new_df.copy()\n",
    "    # If the final dataframe is not empty, merge the new_df with the existing final dataframe using an outer join\n",
    "    else:\n",
    "        final_df = pd.merge(final_df, new_df, on='Email', how='outer', suffixes=('', f'_{keyword}'))\n",
    "\n",
    "# Fill NaN values in the final dataframe\n",
    "final_df = final_df.fillna('')\n",
    "\n",
    "# Now, final_df contains all unique emails from all keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f27449ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165, 15)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2dbd01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd0f78a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60e9dadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Email', 'Career_Action_Plan_(CAP)', 'Comment_Career_Action_Plan_(CAP)',\n",
       "       'Career_Exploration', 'Comment_Career_Exploration', 'CV__Resume',\n",
       "       'Comment_CV__Resume', 'Goal_Setting', 'Comment_Goal_Setting',\n",
       "       'LinkedIn', 'Comment_LinkedIn', 'Searching_Internship',\n",
       "       'Comment_Searching_Internship', 'SMART_goals', 'Comment_SMART_goals'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cfe3cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of columns to assign, excluding 'Email' and columns starting with 'Comment'\n",
    "assign = [col for col in final_df.columns if col != 'Email' and not col.startswith('Comment')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea33abe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leading/trailing spaces in the selected columns\n",
    "final_df[assign] = final_df[assign].applymap(lambda x: x.strip() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b79a9dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['reviewed', 'under review', '', 'rejected'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get unique values of dataframe to see what columns it consist to give 'marks'\n",
    "final_df['Goal_Setting'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aa12d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['reviewed', 'under review', '', 'rejected'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get unique values of dataframe to see what columns it consist to give 'marks'\n",
    "final_df['Goal_Setting'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fa3048",
   "metadata": {},
   "source": [
    "### If you get new unique values in our column then add marks to it. such example \"Pass\" then at Please add pass in below dict and give marks to it like replace_dict = {'under review': 30, 'reviewed': 30,'rejected': 80, 'Pass': 100}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe89a90",
   "metadata": {},
   "source": [
    "# Below you can give marks for Assignment ðŸ‘‡â¬‡ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbc66946",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict = {'under review': 30, 'reviewed': 100,'rejected': 80,'': 0}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edffa64",
   "metadata": {},
   "source": [
    "# ðŸ‘†â˜ï¸\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b511cfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values in selected columns\n",
    "final_df[assign] = final_df[assign].replace(replace_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "761908aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the selected columns to float\n",
    "final_df[assign] = final_df[assign].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c06bff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling NaN Values with zero\n",
    "final_df[assign]=final_df[assign].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "051e3f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of selected columns\n",
    "sum_of_scores = final_df[assign].sum(axis=1)\n",
    "\n",
    "# Count the number of selected columns\n",
    "num_of_columns = len(assign)\n",
    "\n",
    "# Calculate the average score\n",
    "final_df['Assignment_Score'] = sum_of_scores / num_of_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72733354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounding Off values of Assignment score to two digits\n",
    "final_df['Assignment_Score']=final_df['Assignment_Score'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6cee0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling NaN Values with empty\n",
    "final_df=final_df.fillna('')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "caf7a37f",
   "metadata": {},
   "source": [
    "# Replace 'Successfully Submitted ' with an empty string\n",
    "#final_df = final_df.replace('Successfully Submitted ', '# ', regex=True)\n",
    "# Define a custom function to replace the string\n",
    "def replace_string(row):\n",
    "    # Split the row by the string to replace\n",
    "    parts = row.split('Successfully Submitted ')\n",
    "    # Join the parts with the desired replacement\n",
    "    new_row = parts[0] + ''.join(['\\n' + part for part in parts[1:]])\n",
    "    # Return the new row\n",
    "    return new_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "987f60e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.replace('Successfully Submitted ', '# ', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48056999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all columns in the dataframe\n",
    "for col in final_df.columns:\n",
    "    # Check if column name contains '.'\n",
    "    if '.' in col:\n",
    "        # Replace '.' with '_' and remove ' ' only where '.' is present in the column name\n",
    "        new_col = col.replace('.', '_').replace(' ', '') if '.' in col else col\n",
    "        # Rename the column\n",
    "        df.rename(columns={col: new_col}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16cf7493",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Email', 'Career_Action_Plan_(CAP)', 'Comment_Career_Action_Plan_(CAP)',\n",
       "       'Career_Exploration', 'Comment_Career_Exploration', 'CV__Resume',\n",
       "       'Comment_CV__Resume', 'Goal_Setting', 'Comment_Goal_Setting',\n",
       "       'LinkedIn', 'Comment_LinkedIn', 'Searching_Internship',\n",
       "       'Comment_Searching_Internship', 'SMART_goals', 'Comment_SMART_goals',\n",
       "       'Assignment_Score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cheaking the columns present in the dataframe\n",
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8e4b3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(final_df, Kalpana, on='Email', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd92a3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 16)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcdd10a",
   "metadata": {},
   "source": [
    "### The step remaing here is renaming i.e while putting to our mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bccbbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of column names in the final_df\n",
    "column_names = final_df.columns\n",
    "\n",
    "# Iterate through the column names and rename columns starting with \"Comment\"\n",
    "for col in column_names:\n",
    "    if col.startswith(\"Comment\"):\n",
    "        new_col_name = \"Comment\"\n",
    "        final_df = final_df.rename(columns={col: new_col_name})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "397e1109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Email', 'Career_Action_Plan_(CAP)', 'Comment', 'Career_Exploration',\n",
       "       'Comment', 'CV__Resume', 'Comment', 'Goal_Setting', 'Comment',\n",
       "       'LinkedIn', 'Comment', 'Searching_Internship', 'Comment', 'SMART_goals',\n",
       "       'Comment', 'Assignment_Score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the renaming column name\n",
    "final_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bccd6d",
   "metadata": {},
   "source": [
    "# Below insted of renaming name if at staring only we have taken the assignment name as we want mention in txt in source file we will not need to do below step ðŸ‘‡â¬‡ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d82b20a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the column to put in datafarme \n",
    "new_names = {\n",
    "    'SWOT': 'SWOT',\n",
    "    'Career_Action_Plan_(CAP)': 'Career_Action_Plan',\n",
    "    'Goal_Setting' : 'Goal_Setting',\n",
    "    'Critical_thinking': 'Critical_Thinking',\n",
    "    'Masteclass_1_-_Career_Exploration': 'Career_Exploration',\n",
    "    'CV__Resume': 'CV_Resume',\n",
    "    'LinkedIn': 'LinkedIn_Profile',\n",
    "    'Planning_&_Applying_for_Masters_in_India_&_Abroad': 'Planning_Masters',\n",
    "    'RIASEC_personality_test': 'RIASEC',\n",
    "    'SMART_goal': 'SMART_Goal',\n",
    "    'Assignment_Caree' : 'Career_Exploration',\n",
    "    'Career_Exploration' : 'Career_Exploration',\n",
    "    'SMART_goals' : 'SMART_Goal',\n",
    "    'Searching_Internship':'Internship_Searching'\n",
    "}\n",
    "\n",
    "for col in final_df.columns:\n",
    "    if col in new_names:\n",
    "        final_df.rename(columns={col: new_names[col]}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c38ce43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Email', 'Career_Action_Plan', 'Comment', 'Career_Exploration',\n",
       "       'Comment', 'CV_Resume', 'Comment', 'Goal_Setting', 'Comment',\n",
       "       'LinkedIn_Profile', 'Comment', 'Internship_Searching', 'Comment',\n",
       "       'SMART_Goal', 'Comment', 'Assignment_Score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the renaming column name\n",
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3cb7078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the 'comment' in our given format\n",
    "cols = final_df.columns.tolist()\n",
    "new_cols = []\n",
    "prev_col = ''\n",
    "\n",
    "for col in cols:\n",
    "    if col == 'Comment':\n",
    "        new_cols.append(f'Comments_{prev_col}')\n",
    "    else:\n",
    "        new_cols.append(col)\n",
    "    prev_col = col\n",
    "\n",
    "final_df.columns = new_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec422198",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Email', 'Career_Action_Plan', 'Comments_Career_Action_Plan',\n",
       "       'Career_Exploration', 'Comments_Career_Exploration', 'CV_Resume',\n",
       "       'Comments_CV_Resume', 'Goal_Setting', 'Comments_Goal_Setting',\n",
       "       'LinkedIn_Profile', 'Comments_LinkedIn_Profile', 'Internship_Searching',\n",
       "       'Comments_Internship_Searching', 'SMART_Goal', 'Comments_SMART_Goal',\n",
       "       'Assignment_Score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the renaming column name\n",
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6114e35f-9f0e-4ad5-b5d5-fc00f00c97e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "267961bf-559f-4d8f-b010-b1f4d8bd8379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean email addresses\n",
    "def clean_email(email):\n",
    "\n",
    "    # Convert to lowercase and remove extra spaces\n",
    "    cleaned_email = email.lower().strip()\n",
    "    # Remove patterns like \".com.1\"\n",
    "    cleaned_email = re.sub(r'\\.com\\.\\d+', '.com', cleaned_email)\n",
    "    return cleaned_email\n",
    "\n",
    "# Apply the function to the 'email' column\n",
    "final_df['Email'] = final_df['Email'].apply(clean_email)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8616ca-5f26-4912-99b3-10ad072bb16c",
   "metadata": {},
   "source": [
    "# Adding Genral Info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4367da41-eaee-4bf1-95ee-964b70467b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Genral Info\n",
    "gi = pd.read_csv(r\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9959201-60d9-45e6-b635-ceb107f34a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "gi = gi[['Email', 'Name', 'Phone', 'Name_of_College_University','Currently_Pursuing_Degree']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95470eb6-fea4-4177-b0a3-38c304b1d805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with gi\n",
    "output = pd.merge(gi, final_df, on='Email', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e4c8e37-828a-43d6-8918-3126d5203973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Email', 'Name', 'Phone', 'Name_of_College_University',\n",
       "       'Currently_Pursuing_Degree', 'Career_Action_Plan',\n",
       "       'Comments_Career_Action_Plan', 'Career_Exploration',\n",
       "       'Comments_Career_Exploration', 'CV_Resume', 'Comments_CV_Resume',\n",
       "       'Goal_Setting', 'Comments_Goal_Setting', 'LinkedIn_Profile',\n",
       "       'Comments_LinkedIn_Profile', 'Internship_Searching',\n",
       "       'Comments_Internship_Searching', 'SMART_Goal', 'Comments_SMART_Goal',\n",
       "       'Assignment_Score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cbee2f35-5a6f-4517-8164-470ecc71bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange the columns\n",
    "new_column_order = [\n",
    "    'Email', 'Name', 'Phone', 'Name_of_College_University',\n",
    "    'Currently_Pursuing_Degree', 'Goal_Setting', 'Comments_Goal_Setting', \n",
    "    'SMART_Goal', 'Comments_SMART_Goal', 'CV_Resume', \n",
    "    'Comments_CV_Resume', 'Career_Exploration', \n",
    "    'Comments_Career_Exploration', 'Career_Action_Plan', \n",
    "    'Comments_Career_Action_Plan','Internship_Searching',\n",
    "    'Comments_Internship_Searching','LinkedIn_Profile',\n",
    "    'Comments_LinkedIn_Profile', 'Assignment_Score'\n",
    "]\n",
    "\n",
    "output = output[new_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c28d9d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df.to_csv('Career_Exploration_Withcomment.csv', mode='a',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a173df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(r\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1171e4ad-a129-4d9f-b339-1ca8dbbfcfb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Email', 'Career_Action_Plan', 'Comments_Career_Action_Plan',\n",
       "       'Career_Exploration', 'Comments_Career_Exploration', 'CV_Resume',\n",
       "       'Comments_CV_Resume', 'Goal_Setting', 'Comments_Goal_Setting',\n",
       "       'LinkedIn_Profile', 'Comments_LinkedIn_Profile', 'Internship_Searching',\n",
       "       'Comments_Internship_Searching', 'SMART_Goal', 'Comments_SMART_Goal',\n",
       "       'Assignment_Score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b9fc702a-8e16-4ad4-8b65-0d194647cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the column to put in datafarme \n",
    "new_names = {\n",
    "    'Assignment_CAP': 'Career_Action_Plan',\n",
    "    'Comments_Assignment_CAP': 'Comments_Career_Action_Plan',\n",
    "    'Assignment_Career_Exploration' : 'Career_Exploration',\n",
    "    'Comments_Assignment_Career_Exploration': 'Comments_Career_Exploration',\n",
    "    'Assignment_Goal_Setting': 'Goal_Setting',\n",
    "    'Comments_Goal_Setting': 'Comments_Goal_Setting',    \n",
    "    'Goal_Setting': 'Goal_Setting',\n",
    "    'Comments_Goal_Setting': 'Comments_Goal_Setting',\n",
    "    'Assignment_LinkedIn': 'LinkedIn_Profile',\n",
    "    'Comments_Assignment_LinkedIn' : 'Comments_LinkedIn_Profile',\n",
    "    'Planning_&_Applying_for_Masters_in_India_&_Abroad': 'Planning_Masters',\n",
    "    'RIASEC_personality_test': 'RIASEC',\n",
    "    'SMART_goals': 'SMART_Goal',\n",
    "    'Assignment_Searching_&_Securing_Internship' : 'Internship_Searching',\n",
    "    'Comments_Assignment_Searching_&_Securing_Internship' : 'Comments_Internship_Searching',\n",
    "    'Assignment_Resume' : 'CV_Resume',\n",
    "    'Comments_Assignment_Resume' : 'Comments_CV_Resume',\n",
    "    'Assignment_SMART_goals' : 'SMART_Goal',\n",
    "    'Comments_SMART_goals' : 'Comments_SMART_Goal',\n",
    "    'CV__Resume' :'CV_Resume',\n",
    "    'Comments_CV__Resume' : 'Comments_CV_Resume'\n",
    "}\n",
    "\n",
    "for col in final_df.columns:\n",
    "    if col in new_names:\n",
    "        final_df.rename(columns={col: new_names[col]}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "feb39c84-fe29-4a80-bf5e-a4e74440a2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Email', 'Career_Action_Plan', 'Comments_Career_Action_Plan',\n",
       "       'Career_Exploration', 'Comments_Career_Exploration', 'CV_Resume',\n",
       "       'Comments_CV_Resume', 'Goal_Setting', 'Comments_Goal_Setting',\n",
       "       'LinkedIn_Profile', 'Comments_LinkedIn_Profile', 'Internship_Searching',\n",
       "       'Comments_Internship_Searching', 'SMART_Goal', 'Comments_SMART_Goal',\n",
       "       'Assignment_Score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b900c6a",
   "metadata": {},
   "source": [
    "# Storing data on MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1a0341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to MySQL Database\n",
    "conn= msql.connect(host='',user='',password=\"\",database=\"\",auth_plugin='')\n",
    "cursor =conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce48a9d3",
   "metadata": {},
   "source": [
    "â˜ï¸ REMOVE COMMENT OF ABOVE I.E REMOVE #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "edb568b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your existing code for inserting data into the database table\n",
    "for i, row in final_df.iterrows():\n",
    "    row = [None if isinstance(val, float) and math.isnan(val) else val for val in row] # replace \"nan\" values with None\n",
    "    columns = ','.join(final_df.columns)\n",
    "    placeholders = ','.join(['%s']*len(row))\n",
    "    # Construct the INSERT query with ON DUPLICATE KEY UPDATE clause\n",
    "    query = f\"INSERT INTO she_for_stem.11_incubator_assignment_monitoring ({columns}) VALUES ({placeholders}) ON DUPLICATE KEY UPDATE \"\n",
    "    query += \", \".join([f\"{col}=VALUES({col})\" for col in final_df.columns if col != 'Email'])\n",
    "    # Execute the query\n",
    "    cursor.execute(query, tuple(row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e2de36e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e5dbd4-cad1-421c-9476-e76f2d999789",
   "metadata": {},
   "source": [
    "# Storing Data in Supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afc4708-5703-4ff9-97cb-6361a0e9e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supabase URL and API key\n",
    "url = ''\n",
    "api_key = ''\n",
    "\n",
    "\n",
    "# Headers for the request\n",
    "headers = {\n",
    "    'apikey': api_key,\n",
    "    'Authorization': f'Bearer {api_key}',\n",
    "    'Content-Type': 'application/json',\n",
    "    'Prefer': 'resolution=merge-duplicates'  # Enable upsert functionality\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "06b53d0c-a00d-41e6-93c0-aa216a8c8bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final batch of 82 rows upserted successfully\n"
     ]
    }
   ],
   "source": [
    "table_name = '11_incubator_assignment_monitoring'\n",
    "\n",
    "# Batch size for upserting\n",
    "batch_size = 1000  # You can adjust this value based on your performance needs\n",
    "\n",
    "# List to store rows before sending them in batches\n",
    "batch_data = []\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for i, row in final_df.iterrows():\n",
    "    # Replace NaN values with None\n",
    "    row = [None if isinstance(val, float) and math.isnan(val) else val for val in row]\n",
    "    # Convert row to a dictionary\n",
    "    row_dict = dict(zip(final_df.columns, row))\n",
    "    \n",
    "    # Add the row to the batch\n",
    "    batch_data.append(row_dict)\n",
    "    \n",
    "    # If the batch size is reached, send the data\n",
    "    if len(batch_data) >= batch_size:\n",
    "        # Send a batch of rows\n",
    "        response = requests.post(f'{url}/rest/v1/{table_name}', headers=headers, json=batch_data)\n",
    "        \n",
    "        # Check response\n",
    "        if response.status_code in [200, 201]:\n",
    "            print(f'Batch of {len(batch_data)} rows upserted successfully')\n",
    "        else:\n",
    "            print(f'Failed to upsert batch: {response.status_code}, {response.text}')\n",
    "        \n",
    "        # Clear the batch after sending\n",
    "        batch_data = []\n",
    "\n",
    "# Send any remaining rows in the last batch\n",
    "if batch_data:\n",
    "    response = requests.post(f'{url}/rest/v1/{table_name}', headers=headers, json=batch_data)\n",
    "    \n",
    "    if response.status_code in [200, 201]:\n",
    "        print(f'Final batch of {len(batch_data)} rows upserted successfully')\n",
    "    else:\n",
    "        print(f'Failed to upsert final batch: {response.status_code}, {response.text}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc30de38-acaa-412f-8073-785c7cc18bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
