{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3163ae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required modules\n",
    "import pandas as pd\n",
    "import mysql.connector as msql\n",
    "import math\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73d69552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying all columns and rows\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c6648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading She for STEM Incubator file present on source files\n",
    "directory_path =(r\"C:\\Users\\HP\\OneDrive - VigyanShaala\\02 Products  Initiatives\\01 Kalpana\\05 Kalpana M&E\\00 DBMS 1.0\\Kalpana\\Remapping\\Kalpana Source File\\02_Source_Kalpana incubator WN\")\n",
    "csv_files = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(directory_path, file)\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(f\"Data from {file}:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba153b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7912e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of column names to extract for putting into database \n",
    "columns_to_extract = ['Name', 'Email', 'Segment', 'Mobile', 'Enroll Date', 'Assigned Through', 'Course Name']\n",
    "\n",
    "# Use the loc method to extract the specified columns\n",
    "df = data.loc[:, columns_to_extract]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947e066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with 'email' column and columns that start with 'Week' 'Video', 'Recording', and 'Master class'\n",
    "data = data[['Email'] + [col for col in data.columns if col.startswith(('Week','Video', 'SUK', 'Master Class'))]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb40371",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldcol = list(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfb38c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#oldcol =data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14caa5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldcol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0d1325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheaking shape of our dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed3e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables to keep track of the current week, video count, recording count, and master class count\n",
    "week_col = None\n",
    "video_count = 0\n",
    "recording_count = 0\n",
    "master_count = 0\n",
    "\n",
    "# Create an empty list to store the new column names\n",
    "new_cols = []\n",
    "\n",
    "# Iterate over each column in the data\n",
    "for col in data.columns:\n",
    "    # If the column starts with 'Week'\n",
    "    if col.startswith('Week'):\n",
    "        # Split the column name by space and get the second element (the week number)\n",
    "        week_col = col.split()[1]\n",
    "        # Reset the video, recording, and master class counts for the new week\n",
    "        video_count = 0\n",
    "        recording_count = 0\n",
    "    # If the column starts with 'Video'\n",
    "    elif col.startswith('Video'):\n",
    "        # Increment the video count for the current week\n",
    "        video_count += 1\n",
    "        # Append a new column name to the list using f-string formatting\n",
    "        new_cols.append(f'WK{week_col}_V{video_count}')\n",
    "    # If the column starts with 'Recording'\n",
    "    elif col.startswith('SUK'):\n",
    "        # Increment the recording count for the current week\n",
    "        recording_count += 1\n",
    "        # Append a new column name to the list using f-string formatting\n",
    "        new_cols.append(f'WK{week_col}_SUK_V')\n",
    "    # If the column starts with 'Master Class'\n",
    "    elif col.startswith('Master Class'):\n",
    "        # Increment the master class count for the current week\n",
    "        master_count += 1\n",
    "        # Append a new column name to the list using f-string formatting\n",
    "        new_cols.append(f'WK{week_col}_Master{master_count}')\n",
    "    # If the column doesn't start with any of the above prefixes\n",
    "    else:\n",
    "        # Append the original column name to the list\n",
    "        new_cols.append(col)\n",
    "\n",
    "# Remove all columns that start with 'Week' from the data\n",
    "data = data.loc[:, ~data.columns.str.startswith('Week')]\n",
    "# Assign the new column names to the data\n",
    "data.columns = new_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a0f79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rechecking the shape of dataframe\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57433c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheaking columns name\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a347a447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are two columns with the name \"WK8_SUK_V\"\n",
    "if sum(data.columns == 'WK8_SUK_V') == 2:\n",
    "    # Find the index of the last occurrence of \"WK8_SUK_V\"\n",
    "    last_index = data.columns.to_list().index('WK8_SUK_V', -2)\n",
    "\n",
    "    # Change the column name to \"WK8_SUK_V_live\"\n",
    "    data.columns.values[last_index] = 'WK8_SUK_1'\n",
    "    # Find the index of the last occurrence of \"WK8_SUK_V\"\n",
    "    last_index = data.columns.to_list().index('WK8_SUK_V', -1)\n",
    "\n",
    "    # Change the column name to \"WK8_SUK_V_live\"\n",
    "    data.columns.values[last_index] = 'WK8_SUK_2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1b33a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This condition happen beacause we dont have week number before it so it doesnt have week number \n",
    "if 'WKNone_SUK_V' in data.columns:\n",
    "    data = data.rename(columns={'WKNone_SUK_V': 'WK0_SUK_V'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4387bf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheaking for duplicate data\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ae7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locating columns for extracting only numbers\n",
    "col1 = data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f767acc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "col1.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a785de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for extracting only numbers from dataset\n",
    "for column in [i for i in col1.columns if col1[i].dtype == 'object']:\n",
    "    data[column] = data[column].astype(str).str.extract('(\\d+)').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aff28be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Null values with zero\n",
    "fillna = data.iloc[:,1:]\n",
    "fillnacol=fillna.columns\n",
    "data[fillnacol]=data[fillnacol].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac18080",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10feb962",
   "metadata": {},
   "source": [
    "# Enroll Date MySQL Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29288023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new table which for Enroll_Dates which is taken from incubator graphy sheet\n",
    "Enroll=pd.DataFrame(df[[\"Email\", 'Enroll Date']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee1cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting only Enroll_Date\n",
    "Enroll[['Enroll Date','Time']]=Enroll['Enroll Date'].str.split(' ',expand=True)\n",
    "Enroll=Enroll.drop([\"Time\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266cbc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to MySQL Database\n",
    "conn= msql.connect(host='localhost',user='root',password=\"VS@123\",database=\"Kalpana_Incubator_Sept_Dec_2023_Batch\",auth_plugin='mysql_native_password')\n",
    "cursor =conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69960bd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inserting data to 03_enroll_date table\n",
    "for i,row in Enroll.iterrows():\n",
    "    cursor.execute(\"insert IGNORE into 03_enroll_date (Email,Incubator) values(%s,%s)\",tuple(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2360c802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing data  with new data to 03_enroll_date table\n",
    "for i,row in Enroll.iterrows():\n",
    "    cursor.execute(\"REPLACE into 03_enroll_date (Email,incubator) values(%s,%s)\",tuple(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b552e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a887fd3",
   "metadata": {},
   "source": [
    "# Payment details MySQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33fd7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new table which for Payment which is taken from incubator graphy sheet\n",
    "Payment=pd.DataFrame(df[[\"Email\",\"Assigned Through\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e457b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting only Payment removing Order Id\n",
    "Payment[[\"Assigned Through\",\"Order_ID\"]]=Payment[\"Assigned Through\"].str.split(\"-\",expand=True)\n",
    "Payment.drop([\"Order_ID\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2958182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning fee cost to different cathegory of enrollment\n",
    "Payment[\"Assigned Through\"]=Payment[\"Assigned Through\"].replace(['Admin'],'0')\n",
    "Payment[\"Assigned Through\"]=Payment[\"Assigned Through\"].replace(['Excel Upload'],'0')\n",
    "Payment[\"Assigned Through\"]=Payment[\"Assigned Through\"].replace(['Paid Transaction '],'1899')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d3c00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to MySQL Database\n",
    "conn= msql.connect(host='localhost',user='root',password=\"VS@123\",database=\"Kalpana_Incubator_Sept_Dec_2023_Batch\",auth_plugin='mysql_native_password')\n",
    "cursor =conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eb5a3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inserting data into 02_payment_details \n",
    "for i,row in Payment.iterrows():\n",
    "    cursor.execute(\"insert Ignore into 02_payment_details (Email,Incubator_Fee) values(%s,%s)\",tuple(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a1a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing data with new data into 02_payment_details \n",
    "for i,row in Payment.iterrows():\n",
    "    cursor.execute(\"REPLACE into 02_payment_details (Email,Incubator_Fee) values(%s,%s)\",tuple(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69c9abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c17e19c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Changing seconds to Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed22662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving previous column name \n",
    "newcol = list(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbf5a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newcol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0553f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving previous column name for data1 by removing \"Email column\"\n",
    "data_columns = list(data.columns)\n",
    "\n",
    "# Exclude the 'email' column if it exists\n",
    "if 'Email' in data_columns:\n",
    "    data_columns.remove('Email')\n",
    "\n",
    "data1col = data_columns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6631ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldcol = [col for col in oldcol if not col.startswith(\"Week\")]\n",
    "num_columns_to_rename = min(len(data.columns), len(oldcol))\n",
    "data.rename(columns=dict(zip(data.columns[:num_columns_to_rename], oldcol[:num_columns_to_rename])), inplace=True)\n",
    "data.columns = data.columns.str.split (':').str [0]\n",
    "data.columns = data.columns.str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448e4144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_column(col):\n",
    "    # Split the column name by space\n",
    "    parts = col.split()\n",
    "    special_chars = {'!': '1', '@': '2', '#': '3', '$': '4', '%': '5', '^': '6', '&': '7', '*': '8', '?': '9', '+': '0'}\n",
    "    \n",
    "    # If the first part is 'SUK', add the number corresponding to the last character\n",
    "    if parts[0] == 'SUK':\n",
    "        return parts[0] + special_chars.get(parts[1][-1], '0')\n",
    "    \n",
    "    # If the first part is 'Video', use the prefix 'VID' and the numbers corresponding to the last two characters\n",
    "    elif parts[0] == 'Video':\n",
    "        last_char = parts[1][-1]\n",
    "        second_last_char = parts[1][-2] if len(parts[1]) > 1 else '+'\n",
    "        return 'VID' + special_chars.get(second_last_char, '0') + special_chars.get(last_char, '0')\n",
    "    \n",
    "    # If the first part contains 'Master' and 'Class' is present, use the prefix 'MC' and the numbers corresponding to the last two characters\n",
    "    elif 'Master' in parts and 'Class' in parts:\n",
    "        index = parts.index('Master')\n",
    "        last_char = parts[index + 2][-1]\n",
    "        second_last_char = parts[index + 2][-2] if len(parts[index + 2]) > 1 else '+'\n",
    "        return 'MC' + special_chars.get(second_last_char, '0') + special_chars.get(last_char, '0')\n",
    "    \n",
    "    # Otherwise, return the column name as it is\n",
    "    else:\n",
    "        return col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef09c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column names using the rename_column function\n",
    "data.rename(columns=rename_column, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8362edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a978424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Excel file form our source\n",
    "excel_file  = pd.read_excel(r\"C:\\Users\\HP\\OneDrive - VigyanShaala\\02 Products  Initiatives\\01 Kalpana\\05 Kalpana M&E\\00 DBMS 1.0\\Kalpana\\Remapping\\Kalpana Source File\\00_Source_Kalpana Video Details\\Timestamp_of_Videos.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29430c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c753d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each column in the 'data' DataFrame\n",
    "for column_name in data.columns:\n",
    "    # Check if the column exists in the Excel file\n",
    "    if column_name in excel_file['Code'].values:\n",
    "        # Get the corresponding value in the \"Time\" column from the Excel file\n",
    "        value = excel_file.loc[excel_file['Code'] == column_name, 'Time'].values[0]\n",
    "        \n",
    "        # Calculate the percentage value\n",
    "        percentage_value = (data[column_name] * 100) / value\n",
    "        \n",
    "        # Assign the calculated percentage value to a new column in the \"data1\" DataFrame with the same name as the \"Code\" column\n",
    "        data1[column_name] = percentage_value\n",
    "    else:\n",
    "        # Handle the case when the column is present in 'data' but not in the Excel file\n",
    "        print(f\"Column '{column_name}' present in 'data' but not in the Excel file. Skipping.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e259cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each row in the Excel file\n",
    "for index, row in excel_file.iterrows():\n",
    "    # Get the value in the \"Code\" column\n",
    "    column_name = row['Code']\n",
    "    \n",
    "    # Get the value in the \"Time\" column\n",
    "    value = row['Time']\n",
    "    \n",
    "    # Check if the 'Code' column exists in the 'data' DataFrame\n",
    "    if column_name in data.columns:\n",
    "        # Calculate the percentage value\n",
    "        percentage_value = (data[column_name] * 100) / value\n",
    "        \n",
    "        # Assign the calculated percentage value to a new column in the \"data1\" DataFrame with the same name as the \"Code\" column\n",
    "        data1[column_name] = percentage_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b57c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19289c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing column name back to new column\n",
    "data.columns = newcol \n",
    "data1.columns = data1col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7b5ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ce69ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1ed33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function \"Max_Value\" for converting % max 100 if values are above 100\n",
    "def Max_Value(value):\n",
    "    if value >=100:\n",
    "        return 100\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf6adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Max_Value function\n",
    "per1=data1.iloc[:,0:]\n",
    "per1c=per1.columns\n",
    "data1[per1c]=data1[per1c].applymap(Max_Value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aa7b1a",
   "metadata": {},
   "source": [
    "# Code for converting seconds to hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b941d2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function for converting seconds to hours\n",
    "def Convert_Hours(seconds):\n",
    "    hours = seconds / (3600)\n",
    "    return hours\n",
    "n = 5400\n",
    "print(Convert_Hours(n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0975e96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Convert_Hours function\n",
    "col1 = data.iloc[:,1:]\n",
    "col=col1.columns\n",
    "data[col]=data[col].apply(Convert_Hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3744605c",
   "metadata": {},
   "source": [
    "# Code for Recorded Videos: Total hours, Average & Percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d38d5a7",
   "metadata": {},
   "source": [
    "## Input Weeks Here ↓ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3047c32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the week number up to which you want to include columns\n",
    "end_week = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9db805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all column names up to the end week\n",
    "cols_to_select = []\n",
    "for week in range(end_week + 1):\n",
    "    for video in range(1, 10):\n",
    "        col_name = f'WK{week}_V{video}'\n",
    "        if col_name in data.columns:\n",
    "            cols_to_select.append(col_name)\n",
    "\n",
    "# Select the desired columns and create a new DataFrame\n",
    "Recorded_Total = data[cols_to_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95549994",
   "metadata": {},
   "outputs": [],
   "source": [
    "Recorded_Total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2955953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Recorded_Total\"]=Recorded_Total.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acfe145",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Recorded_Average\"]=Recorded_Total.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6267a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all column names up to the end week\n",
    "cols_to_select_per = []\n",
    "for week in range(end_week + 1):\n",
    "    for video in range(1, 10):\n",
    "        col_name = f'WK{week}_V{video}'\n",
    "        if col_name in data1.columns:\n",
    "            cols_to_select_per.append(col_name)\n",
    "\n",
    "# Select the desired columns and create a new DataFrame\n",
    "Recorded_Percent = data1[cols_to_select_per]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95b4ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Recorded_Percent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e886f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Recorded_Percentage\"]=Recorded_Percent.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4f68a5",
   "metadata": {},
   "source": [
    "# Code for SUK Recorded Videos: Total hours, Average & Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84e6385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all column names up to the end week\n",
    "cols_to_select = []\n",
    "for week in range(end_week + 1):\n",
    "    col_name = f'WK{week}_SUK_V'\n",
    "    if col_name in data.columns:\n",
    "        cols_to_select.append(col_name)\n",
    "\n",
    "# Select the desired columns and create a new DataFrame\n",
    "SUK_Recorded_Total = data[cols_to_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d15c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUK_Recorded_Total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3cc323",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"SUK_Recorded_Total\"]=SUK_Recorded_Total.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a4cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"SUK_Recorded_Average\"]=SUK_Recorded_Total.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bcb0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all column names up to the end week\n",
    "cols_to_select = []\n",
    "for week in range(end_week + 1):\n",
    "    col_name = f'WK{week}_SUK_V'\n",
    "    if col_name in data1.columns:\n",
    "        cols_to_select.append(col_name)\n",
    "\n",
    "# Select the desired columns and create a new DataFrame\n",
    "SUK_Recorded_Percent = data1[cols_to_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d40f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"SUK_Recorded_Percentage\"]=SUK_Recorded_Percent.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20013b8e",
   "metadata": {},
   "source": [
    "# Code for Master Class: Total hours, Average & Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac9a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all column names up to the end week\n",
    "cols_to_select = []\n",
    "for week in range(end_week + 2):\n",
    "    for masterclass in range(1, 10):\n",
    "        col_name = f'WK{week}_Master{masterclass}'\n",
    "        if col_name in data.columns:\n",
    "            cols_to_select.append(col_name)\n",
    "\n",
    "# Select the desired columns and create a new DataFrame\n",
    "Masterclass_Total = data[cols_to_select]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e17d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Masterclass_Total\"]=Masterclass_Total.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4748071",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Masterclass_Average\"]=Masterclass_Total.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aac8c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all column names up to the end week\n",
    "cols_to_select = []\n",
    "for week in range(end_week + 1):\n",
    "    for masterclass in range(1, 10):\n",
    "        col_name = f'WK{week}_Master{masterclass}'\n",
    "        if col_name in data1.columns:\n",
    "            cols_to_select.append(col_name)\n",
    "\n",
    "# Select the desired columns and create a new DataFrame\n",
    "Masterclass_Percent = data1[cols_to_select]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e0e711",
   "metadata": {},
   "outputs": [],
   "source": [
    "Masterclass_Percent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f5082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Masterclass_Percentage\"]=Masterclass_Percent.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63929f07",
   "metadata": {},
   "source": [
    "# Code for Program: Total hours, Average & Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cebd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns from data where the column names start with \"WK\"\n",
    "selected_cols = [col for col in data.columns if col.startswith('WK')]\n",
    "\n",
    "# create a new dataframe called Whole_Program_Total with the selected columns\n",
    "Whole_Program_Total = data[selected_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eacfd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "Whole_Program_Total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c11f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Program_Total\"]=Whole_Program_Total.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabd0206",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[\"Program_Average\"]=Whole_Program_Total.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66baeb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns from data where the column names start with \"WK\"\n",
    "selected_cols = [col for col in data1.columns if col.startswith('WK')]\n",
    "\n",
    "# create a new dataframe called Whole_Program_Total with the selected columns\n",
    "Whole_Program_Percent = data1[selected_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23c8fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Program_percentage\"]=Whole_Program_Percent.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eab004",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56dd896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving In Database\n",
    "data.to_csv(r\"C:\\Users\\HP\\OneDrive - VigyanShaala\\02 Products  Initiatives\\01 Kalpana\\05 Kalpana M&E\\00 DBMS 1.0\\Kalpana\\Remapping\\Kalpana Output\\Incubator_and_attendence_monitoring_Sep_2023.csv\",mode='w',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee03d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20d19f3a",
   "metadata": {},
   "source": [
    "# Incubator and attendance monitoring MySQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a0da8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b25aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c052e8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c38894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9689969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldcol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68cbbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldcol = [col for col in oldcol if not col.startswith(\"Week\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7a2173",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldcol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44870a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.columns = oldcol[:len(data.columns)]\n",
    "# Now, let's say you want to change the column names of 'old_dataset' based on 'filtered_column_names'\n",
    "num_columns_to_rename = min(len(data.columns), len(oldcol))\n",
    "print(num_columns_to_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ccc2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns=dict(zip(data.columns[:num_columns_to_rename], oldcol[:num_columns_to_rename])), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d960fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce10e063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the columns by ':' and keep only the first part\n",
    "data.columns = data.columns.str.split (':').str [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19babfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6627f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data.columns.str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8938f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_column(col):\n",
    "    # Split the column name by space\n",
    "    parts = col.split()\n",
    "    special_chars = {'!': '1', '@': '2', '#': '3', '$': '4', '%': '5', '^': '6', '&': '7', '*': '8', '?': '9', '+': '0'}\n",
    "    \n",
    "    # If the first part is 'SUK', add the number corresponding to the last character\n",
    "    if parts[0] == 'SUK':\n",
    "        return parts[0] + special_chars.get(parts[1][-1], '0')\n",
    "    \n",
    "    # If the first part is 'Video', use the prefix 'VID' and the numbers corresponding to the last two characters\n",
    "    elif parts[0] == 'Video':\n",
    "        last_char = parts[1][-1]\n",
    "        second_last_char = parts[1][-2] if len(parts[1]) > 1 else '+'\n",
    "        return 'VID' + special_chars.get(second_last_char, '0') + special_chars.get(last_char, '0')\n",
    "    \n",
    "    # If the first part contains 'Master' and 'Class' is present, use the prefix 'MC' and the numbers corresponding to the last two characters\n",
    "    elif 'Master' in parts and 'Class' in parts:\n",
    "        index = parts.index('Master')\n",
    "        last_char = parts[index + 2][-1]\n",
    "        second_last_char = parts[index + 2][-2] if len(parts[index + 2]) > 1 else '+'\n",
    "        return 'MC' + special_chars.get(second_last_char, '0') + special_chars.get(last_char, '0')\n",
    "    \n",
    "    # Otherwise, return the column name as it is\n",
    "    else:\n",
    "        return col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d79d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column names using the rename_column function\n",
    "data.rename(columns=rename_column, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2c6fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40edf405",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a002ea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data.columns.duplicated().sum()\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb154fd",
   "metadata": {},
   "source": [
    "# Storing data on MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f7a679",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = df.merge(data, on ='Email', how = 'inner') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cd1831",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.drop('Enroll Date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed57bf09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged = merged.rename(columns={'Assigned Through': 'Assigned_Through'})\n",
    "merged = merged.rename(columns={'Mobile': 'Phone'})\n",
    "merged = merged.rename(columns={'Course Name': 'Course_Name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff413e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d456bd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn= msql.connect(host='localhost',user='root',password=\"VS@123\",database=\"kalpana\",auth_plugin='mysql_native_password')\n",
    "cursor =conn.cursor() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cbb91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the existing columns in the database\n",
    "cursor.execute(\"SHOW COLUMNS FROM 08_incubator_and_attendance_monitoring\")\n",
    "existing_columns = [col[0] for col in cursor.fetchall()]\n",
    "\n",
    "# Define the column name before which the new column should be added\n",
    "target_column = 'Recorded_Total'\n",
    "\n",
    "# Check if any new columns exist in the dataframe but not in the database\n",
    "new_columns = [col for col in merged.columns if col not in existing_columns]\n",
    "if new_columns:\n",
    "    # Add new columns to the database before the target column\n",
    "    for col in reversed(new_columns):\n",
    "        if col not in existing_columns:\n",
    "            # Get the index of the target column\n",
    "            target_column_index = existing_columns.index(target_column)\n",
    "            # Set the data type based on whether the column name starts with Comment\n",
    "            data_type = \"INT\" \n",
    "            alter_query = f\"ALTER TABLE 08_incubator_and_attendence_monitoring ADD COLUMN {col} {data_type} AFTER {existing_columns[target_column_index - 1]}\"\n",
    "            cursor.execute(alter_query)\n",
    "            existing_columns.insert(target_column_index - 1, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c532992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your existing code for inserting data into the database table\n",
    "for i, row in merged.iterrows():\n",
    "    row = [None if isinstance(val, float) and math.isnan(val) else val for val in row] # replace \"nan\" values with None\n",
    "    columns = ','.join(merged.columns)\n",
    "    placeholders = ','.join(['%s']*len(row))\n",
    "    # Construct the INSERT query with ON DUPLICATE KEY UPDATE clause\n",
    "    query = f\"INSERT INTO 08_incubator_and_attendance_monitoring ({columns}) VALUES ({placeholders}) ON DUPLICATE KEY UPDATE \"\n",
    "    query += \", \".join([f\"{col}=VALUES({col})\" for col in merged.columns if col != 'Email'])\n",
    "    # Execute the query\n",
    "    cursor.execute(query, tuple(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6764e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76f135a",
   "metadata": {},
   "source": [
    "# Extracting desire output to excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba955e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4d3a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b1dc9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
